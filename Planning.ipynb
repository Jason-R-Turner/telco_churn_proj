{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac3acb8-bfa0-4317-8bb9-2fa9f00a1110",
   "metadata": {},
   "source": [
    "# Classification Project\n",
    "\n",
    "## Project Objectives\n",
    "\n",
    "- Document code, process (data acquistion, preparation, exploratory data analysis and statistical testing, modeling, and model evaluation), findings, and key takeaways in a Jupyter Notebook Final Report.\n",
    "\n",
    "- Create modules (acquire.py, prepare.py) that make your process repeateable and your report (notebook) easier to read and follow.\n",
    "\n",
    "- Ask exploratory questions of your data that will help you understand more about the attributes and drivers of customers churning. Answer questions through charts and statistical tests.\n",
    "\n",
    "- Construct a model to predict customer churn using classification techniques, and make predictions for a group of customers.\n",
    "\n",
    "- Refine your work into a Report, in the form of a jupyter notebook, that you will walk through in a 5 minute presentation to a group of collegues and managers about the work you did, why, goals, what you found, your methdologies, and your conclusions.\n",
    "\n",
    "- Be prepared to answer panel questions about your code, process, findings and key takeaways, and model.\n",
    "\n",
    "## Business Goals\n",
    "\n",
    "- Find drivers for customer churn at Telco. Why are customers churning?\n",
    "\n",
    "- Construct a ML classification model that accurately predicts customer churn.\n",
    "\n",
    "- Deliver a report that a non-data scientist can read through and understand what steps were taken, why and what was the outcome?\n",
    "\n",
    "## Audience\n",
    "\n",
    "- Your target audience for your notebook walkthrough is your direct manager and their manager. This should guide your language and level of explanations in your walkthrough.\n",
    "## Deliverables\n",
    "\n",
    "**You are expected to deliver the following:**\n",
    "\n",
    "### Github repo with the following:\n",
    "\n",
    "1. **Readme (.md)**\n",
    "\n",
    "- project description with goals\n",
    "\n",
    "- initial hypotheses and/or questions you have of the data, ideas\n",
    "\n",
    "- data dictionary\n",
    "\n",
    "- project planning (lay out your process through the data science pipeline)\n",
    "\n",
    "- instructions or an explanation of how someone else can reproduce your project and findings (What would someone need to be able to recreate your project on their own?)\n",
    "\n",
    "- key findings, recommendations, and takeaways from your project.\n",
    "\n",
    "2. **Final Report (.ipynb)** (see details above in the \"Jupyter Notebook Report\")\n",
    "\n",
    "- A **Report** that has filtered out all the extraneous elements not necessary to include in the report.\n",
    "\n",
    "- Use markdown throughout the notebook to guide the audience. Assume the reader will not read your code blocks as you think about how much markdown guidance do you need.\n",
    "\n",
    "- Then, assume another reader will read ALL of your code, so make sure it is very very clearly commented. All cells with code need comments.\n",
    "\n",
    "- Your notebook should begin with a project overview and goals and end with a conclusion that talks about your original goals and how you reached those (or didn't), the key findings, recommendations and next steps (\"If I had more time, I would...\")\n",
    "\n",
    "- Exploration should be refined in the report because now you know which visualizations and tests led to valuable outcomes.\n",
    "\n",
    "- Include at least 4 visualizations in the form of:\n",
    "\n",
    "    a. Question in markdown that you want to answer\n",
    "\n",
    "    b. visualization\n",
    "\n",
    "    c. statistical test (in at least 2 of your 4)\n",
    "\n",
    "    d. Provide your clear answer or takeaway in markdown and natural language to the question based on your exploration.\n",
    "\n",
    "- Provide the context of the target variable through a visualization (distribution of the values, e.g.)\n",
    "\n",
    "- Include your 3 best models in the final notebook to review. Show the steps and code you went through to fit the models, evaluate, and select.\n",
    "\n",
    "- On your best model, a chart visualizing how it performed on test would be valuable.\n",
    "\n",
    "3. **Acquire & Prepare Modules (.py)**\n",
    "\n",
    "- contains functions to acquire, prepare and split your data. You can have other .py files if you desire to abstract other code away from your final report.\n",
    "\n",
    "- Your work must be reproducible by someone with their own `env.py` file.\n",
    "\n",
    "- Each of your functions are complimented with docstrings. If they are functions you borrowed from instructors, put those docstrings in your own words.\n",
    "\n",
    "- Functions to acquire and prepare your data should be imported and used in your final report.\n",
    "\n",
    "4. A **Predictions (.csv).**\n",
    "\n",
    "- 3 columns: customer_id, probability of churn, and prediction of churn. (1=churn, 0=not_churn).\n",
    "\n",
    "- These predictions should be from your best performing model ran on `X_test`.\n",
    "\n",
    "- Note that the order of the `y_pred` and `y_proba` are numpy arrays coming from running the model on `X_test`. The order of those values will match the order of the rows in `X_test`, so you can obtain the customer_id from `X_test` and concatenate these values together into a dataframe to write to CSV.\n",
    "\n",
    "5. 1+ non-final Notebooks (.ipynb) created while working on the project, containing exploration & modeling work (and other work)\n",
    "\n",
    "## Live Presentation\n",
    "\n",
    "- A **live presentation** where you deliver the **final report** (.ipynb) (your final notebook) and walk through it with the audience.\n",
    "\n",
    "- *If have content that you intend to skip in your presentation, it should not be included in your report, like scrolls and scrolls of visualizations*. Remember, this is a different artifact from the notebook you worked on that contains all your work. This serves a purpose of conveying information to others. And you will use it to give an overview of your project by walking through the main steps (what cleaning did you do and why, what insights did you find in exploration, what are 3 models you developed, how did the differ, and how did they compare in terms of performance? What was the best model and how do you expect it to perform in production on data it's never seen? And finally, wrap it all up in a conclusion. (5 minutes max). *You should be prepared to answer follow-up questions about your code, process, tests, model, and findings*.\n",
    "\n",
    "- You will have created multiple notebooks in your work. Do not be concerned about not showing all your work in your report. That is not intended. We can look back to see the work that let to your final notebook. But we want you to feel comfortable creating a report from your work that gives brief insight into the findings and how you got those findings. This is the first step of you practicing delivering a report that is abstracted away from all the details. It takes practice to feel comfortable not showing everything. It will get easier the more you practice.\n",
    "\n",
    "## Tips\n",
    "\n",
    "**Sample questions**\n",
    "\n",
    "- Are customers with DSL more or less likely to churn?\n",
    "- What month are customers most likely to churn and does that depend on their contract type?\n",
    "- Is there a service that is associated with more churn than expected?\n",
    "- Do customers who churn have a higher average monthly spend than those who don't?\n",
    "\n",
    "**Making recommendations**\n",
    "\n",
    "Recommendations should be feasible. If you find that month-to-month customers churn more, we won't be surprised, but Telco is not getting rid of that plan. The fact that customers churn is not because they can; it's because they can and they are motivated to do so. We want your insights into why they are motivated to do so. We realize you will not be able to do a full causal experiment, but we would like to see some solid evidence of your conclusions.\n",
    "\n",
    "**The pipeline**\n",
    "\n",
    "To step through each step in the pipeline, refer to the lessons in classification. This project is intended to pull together what you have done in this module. So use those resources. If you need a refresher on the pipeline and the goals in each stage, refer to the lesson in fundamentals: [Data Science Pipeline](https://ds.codeup.com/fundamentals/data-science-pipeline/).\n",
    "\n",
    "**Data Prep**\n",
    "\n",
    "Prepare your data within the notebook first. Line by line, testing the functionality. Then define the function (with docstrings, of course), in the notebook. Run the function, in the notebook. Make sure it works as expected before sending it to the prepare.py module. If you run into errors later, bring it back into the notebook and work backwards...take it out of the function, then run it. Still issues, take out line by line to find where the error is. Don't put it back into the prepare.py until you know it is working! And remember, restart your kernel before trying again!!\n",
    "\n",
    "**Time management**\n",
    "\n",
    "The hardest part of this first DS project is time management. *Don't skip planning*. And in planning, write the questions you intend to answer in exploration. This is where you can fall down the rabbit hole (exploration + coming up with new features). Complete an MVP before diving deeper. So write questions to answer before you even touch code. When you get to exploration, answer only those questions first, limit the time you allow yourself to create new features. Answer the minimum of 4 questions, create viz's, run tests, then move on. Fit 3 models with train, predict and evaluate with train. Evaluate with validate, select the best, and then evaluate on test. Make a copy of the notebook.\n",
    "\n",
    "One will become your report. Add the markdown at the top of the report (intro, project overview, goals, etc.), add the markdown of what you are doing to prepare the data, make sure the exploration is well documented where you can walk through each question, viz/test, and answer individually. Add a summary of your exploration findings to the end of your explore section. Enhance the markdown around your modeling stage. Which eval metric did you use and why? Which performed the best and why? Add a visual of your best model showing how it performed. Add a solid conclusion with how you achieved the goals, key takeaways, next steps, how you expect the predictions you made on the customers (in the csv) to perform, and recommendations to help reduct churn and improve customer retention.\n",
    "\n",
    "Once you have finished all that and made sure your code is commented and all deliverables are ready to go, then you can go back (in your original working notebook...NOT your report), and do more exploration or modeling! If you find something you want to add before you deliver it, cool. If you don't, no problem because you already have an MVP, Minimally Viable Product!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a039f07-a3b2-49bd-bc43-a6069881101f",
   "metadata": {},
   "source": [
    "# Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2399b1f-3cff-4c43-9109-ecb80d8b9dfe",
   "metadata": {},
   "source": [
    "## Create modules making sure they have docstrings in your own words\n",
    "- ✅ acquire.py\n",
    "- ✅ prepare.py\n",
    "- ✅ env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356f429-4b04-4a4d-9259-6ce0d05d861e",
   "metadata": {},
   "source": [
    "## Questions to answer in exploration\n",
    "similar to the following:\n",
    "- Are customers with DSL more or less likely to churn?\n",
    "- What month are customers most likely to churn and does that depend on their contract type?\n",
    "- Is there a service that is associated with more churn than expected?\n",
    "- Do customers who churn have a higher average monthly spend than those who don't?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc21616-7ca9-4a6f-b9ab-e9920d10fee7",
   "metadata": {},
   "source": [
    "1. ✅ Question 1 -  Do customers who use Tech Support churn at a significantly different rate and if so is it more or less?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54af9d-09ce-4159-ba60-298c60c475c2",
   "metadata": {},
   "source": [
    "2. ✅ Question 2 - What are the rates of churn of 1 and 2 year contracts both before and after fullfilling their obligations as compared to month-to-month contracts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f385d-d131-4340-837d-595a7c38a4db",
   "metadata": {},
   "source": [
    "3. ✅ Question 3 - What group of customers pay the most in monthly charges but are at or below the average churn rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa9b65-af6a-4239-a287-43c1a69415be",
   "metadata": {},
   "source": [
    "4. ✅ Question 4 - What services offered show the lowest rates of overall churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3712604d-5959-4dfd-bfa5-31d6b8d72b4d",
   "metadata": {},
   "source": [
    "## Create at least 4 different visualizations that have the following:\n",
    "a. 1️⃣ 2️⃣ 3️⃣ 4️⃣ A question in **markdown** that you want to answer\n",
    "\n",
    "b. 1️⃣ 2️⃣ A visualization\n",
    "\n",
    "c. 1️⃣ A statistical test (in at least 2 of your 4)\n",
    "\n",
    "d. 1️⃣ 2️⃣ A clear answer or takeaway in **markdown** and natural language to the question based on your exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd205d9-4200-43c4-af07-4a2d46622faf",
   "metadata": {},
   "source": [
    "## Tests to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae95aad-a64b-4bab-8d9f-c89d02fb77df",
   "metadata": {},
   "source": [
    "## Fit 3 models using the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f021a07-dc37-4ff1-ace4-085d95e16e52",
   "metadata": {},
   "source": [
    "1. train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648efb3-a678-4022-a68b-2fb8b61913ae",
   "metadata": {},
   "source": [
    "2. predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583381e3-3773-44bc-ad14-08ce1cd9f75c",
   "metadata": {},
   "source": [
    "3. evaluate with train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c574b19e-55cf-4999-a943-515303fbbade",
   "metadata": {},
   "source": [
    "## Select the best model by evaluating with validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a73789-929f-4471-a828-fdf8fe3d840f",
   "metadata": {},
   "source": [
    "## Evaluate best model on test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbc363-313e-48cd-9217-e4532141f4f7",
   "metadata": {},
   "source": [
    "## Make a Predictions.csv file with the following:\n",
    "- 3 columns: `customer_id`, `probability of churn`, and `prediction of churn`. (1=churn, 0=not_churn).\n",
    "- These predictions should be from your best performing model ran on `X_test`.\n",
    "- Note that the order of the `y_pred` and `y_proba` are numpy arrays coming from running the model on `X_test`. The order of those values will match the order of the rows in `X_test`, so you can obtain the customer_id from `X_test` and concatenate these values together into a dataframe to write to CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63739fd-5ae9-4a00-9eae-24a14d480b93",
   "metadata": {},
   "source": [
    "## Make copy of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7440673a-fe94-45c7-8bc4-d104478fe7f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One will be your report name `Final_Report.ipynb` with markdown with the following sections:\n",
    "- Intro\n",
    "- Project overview\n",
    "- Goals\n",
    "    - Find driver for customer churn at Telco. Why are customers churning?\n",
    "    - Make a report that non-data scientists can understand\n",
    "    - Target audience is your manager and their manager\n",
    "    - Make predictions here??\n",
    "- Exploration\n",
    "    - Summary\n",
    "- Modeling - enhance markdown here\n",
    "    - Which eval metric did you use and why?\n",
    "    - Which performed the best and why?\n",
    "    - Add viz of best model showing its performance\n",
    "- Conclusion\n",
    "    - Goals achieved\n",
    "    - Key takeaways\n",
    "    - Next steps\n",
    "    - Prediction performance expectations\n",
    "    - Recommendations to reduce churn\n",
    "- Etc.\n",
    "Walk through and explain what you did to prepare the data and answer each viz/test individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a5c05-ecca-452a-91ca-b73e620e546f",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "- Comment out code including .py files\n",
    "- Make Readme (.md) file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bccde-b159-4313-8cba-5af1cd41701f",
   "metadata": {},
   "source": [
    "## Practice 5 minute presentation\n",
    "- Be ready to answer questions about the following:\n",
    "     - Code\n",
    "     - Process\n",
    "     - Findings\n",
    "     - Key takeaways\n",
    "     - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359dabf-e8e8-45e4-b96b-ad16ae12c86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
